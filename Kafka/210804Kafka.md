# kafka를 알아보게 된 계기

* https://www.educba.com/kafka-vs-spark/

* https://www.knowledgehut.com/blog/big-data/kafka-vs-spark

* 빅데이터 생태계에서 실시간 데이터 처리를 어떻게 하느냐에 대한 궁금증

  * spark
    * cluster computing system
    * 배치작업이나 실시간 스트리밍이 가능
    * 데이터 가공 가능
    * 하지만, 여기서 말하는 실시간 스트리밍은 타임 윈도로 분할한 스트림 데이터에 일괄 처리를 적용하는 것으로, 여러 개의 작은 데이터들을 처리하는 OLTP에는 적합하지않다(분산 아키텍처 때문에 처리 시간에 오버헤드가 발생해서)
    * scaling하려면 재설정이 필요하다(standalone framework)
    * kafka->database, kafka->data science model 로 데이터가 이동할 때 spark stream이 적당
    * 여러 개의 row를 처리하는데 좋다(batch processing)
  * kafka
    * stream processing platform
    * 실시간 스트리밍 가능
    * 데이터 가공 가능(kafka streams)
    * per-second stream processing을 millisecond 단위의 지연시간으로 처리 가능
    * java process들만 더 추가하면 scaling이 쉽게 된다(microservice library)
    * kafka->kafka로 데이터가 이동할 때 kafka stream이 적당
    * 진정한 의미에서 a-record-at-a-time 처리를 하고, rows parsing, data cleansing등에 좋다
    * 데이터 무결성

* kafka와 spark의 주요 사용사례

  ![kafka vs spark ](210804kafka.assets/kafka-vs-spark-1.png)

* 어떤 것이 더 좋은 설계일까

  * https://dzone.com/articles/is-apache-kafka-a-database-the-2020-update

  * https://engineering.linecorp.com/ko/blog/line-shopping-platform-kafka-mongodb-kubernetes/

    * LINE 쇼핑 플랫폼의 사례

    * 전에는 Oracle

    * 후에는 MongoDB/MySQL->Kafka

      * 데이터를 이벤트 기반으로 처리하고, 스키마에 종속적이지 않으면서, 스케일 아웃이 가능하고, 서버를 쉽게 구성하고 자원을 효율적으로 사용하기 위해 도입
      * 먼저 판매자 데이터가 kafka를 통해 들어옴
      * kafka에서 mongodb로 변경내용 있으면 전달
      * mongodb가 업데이트되면 kafka connect가 감지하여 kafka topic에 저장
      * MongoDB/MySQL에 로그가 쌓일 때마다 Kafka Connect가 변경을 감지해 Kafka에 전달

      ![img](210804kafka.assets/lineshopping1)

      ![img](210804kafka.assets/lineshopping2)

  * 웹 크롤러 with 파싱->kafka->db

  * 웹 크롤러 with 파싱->db

  * 웹 크롤러->kafka->spark->db

* 다양한 데이터 producer, consumer 간의 크기가 작지만 많은 데이터를 실시간으로 처리하는 방법부터 배우고 싶었다.

# kafka의 주요 특징

* https://twofootdog.tistory.com/86
* 메시징을 보내는 역할과 받는 역할이 분리
  * Publish and Subscribe
  * Producer : 카프카로 메시지를 보내기만 함
  * Consumer : 카프카에서 메시지를 가져오기만 함
  * 이러한 구조는 한 쪽 시스템에 문제가 발생해도 전체 시스템에 영향이 가지 않는다
* 하나의 토픽에 여러 Producer, Consumer가 접근 가능
  * sources와 sinks의 Integration
* 디스크에 메시지를 저장하고 유지
  * Store(fault-tolerant)
  * 정해져 있는 보관 주기 동안 디스크에 메시지를 저장
  * 트래픽이 일시적으로 많아지거나 컨슈머에 오류가 있더라도 메시지 손실 없이 작업 가능
* 이벤트 스트림 실시간처리
  * real-time stream process
* 확장용이
  * 하나의 카프카 클러스터는 3개이상의 브로커로 확장이 가능하다
* 성능이 높다
  * 내부적으로 분산처리, 배치처리 등의 기법을 사용하여 링크드인에서 1조개의 메시지를 생성하고 1PB 이상의 데이터 처리를 했다

# kafka with python producer

* https://needjarvis.tistory.com/607

# kafka main comcept and terminology

* https://kafka.apache.org/intro
* event : 무언가 일어난 일에대해 다음과 같이 key, value, timestamp, optional metadata로 이루어진 레코드
  * key : "Alice"
  * value : "Made a payment of $200 to Bob"
  * timestamp: "Jun. 25, 2020 at 2:06 p.m."
* producer : kafka에 이벤트를 쓰는 client application
* consumer : 이벤트들을 읽고 처리하는 client application
* topic : 이벤트들을 저장하는 곳. 항상 multi-producer와 multi-subscriber를 가진다(0개 이상)
* producer와 consumer는 서로 완벽하게 분리되어 있어서 high scalability가 가능하다
* 이벤트들은 잘 조직되어 topic에 저장된다.
* 다른 기존의 messaging system과 달리 이벤트들은 consumption이후 지워지지 않는다(남아있을 기간 설정 가능)
* kafka는 데이터 크기와 상관없이 성능이 일정하다.
* topic은 파티션으로 나누어져있다.
  * topic은 다른 kafka broker들에 있는 여러개의 bucket들에 퍼져있다.
  * 같은 key를 가진 이벤트들이 같은 partition에 시간순서대로 쌓여 consumer가 항상 쓰여진 순서 그대로 읽는 것을 보장한다.
* fault-tolerant하고 highly-available하려면 모든 topic들은 복제되어 여러 broker들에 저장되어야 한다. 기본 replication factor는 3이고 이러한 복제과정은 topic partition 단위에서 일어난다.

# kafka docker로 설치 및 실행

* https://hub.docker.com/r/bitnami/kafka

* https://medium.com/@mazdah70/apache-kafka-%EC%8B%9C%EC%9E%91%ED%95%98%EA%B8%B0-2c0c3e7195cd

* https://epicdevs.com/17?category=460351

* kafka 실행

  * 다음과 같이 실행

    ![image-20210803093739199](210804Kafka.assets/image-20210803093739199.png)

  * kafka가 정상적으로 실행되지 않았던 때
    * kafka.common.inconsistentclusteridexception the cluster id doesn't match~
    * 카프카 로그 path의 meta.properties라는 파일을 지워주면 해결
    * 아예 kafka-data 볼륨을 설정하지 않는 걸로 해결
    
  * 먼저 토픽 생성
  
    ```shell
    docker exec -it kafka sh
    kafka-topics.sh --create --topic quickstart-events --bootstrap-server localhost:9092
    ```
  
  * 간단한 producer, consumer 생성
  
    * producer에서 메시지를 쓰자 약 1초만에 consumer에서 똑같은 메시지를 띄움
  
    * key값도 지정해서 보내주기 위해 parse.key=true 설정, key를 받았다는 것을 보여주기 위해 print.key=true 설정
  
      ```shell
      # consumer
      kafka-console-consumer.sh --topic quickstart-events --from-beginning --bootstrap-server localhost:9092
      kafka-console-consumer.sh --topic quickstart-events --from-beginning --bootstrap-server localhost:9092 --property print.key=true --property print.value=true --property key.separator="-"
      # producer
      kafka-console-producer.sh --topic quickstart-events --bootstrap-server localhost:9092
      kafka-console-producer.sh --topic quickstart-events --bootstrap-server localhost:9092 --property parse.key=true --property key.separator=:
      ```
  
      
  
    ![image-20210804112556917](210804Kafka.assets/image-20210804112556917.png)
  
    ![image-20210804202911716](210804Kafka.assets/image-20210804202911716.png)